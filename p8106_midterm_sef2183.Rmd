---
title: "P8106 Data Science II Midterm Project Report: Predicting COVID-19 Recovery Time and Identifying Important Risk Factors"
author: "Sarah Forrest - sef2183"
date: "4/5/2023"
output: github_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE, dpi = 300, fig.width = 7)
```

```{r, include = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(mgcv)
library(earth)
```

# Background

To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic. The ultimate goal is to develop a prediction model for recovery time and identify important risk factors for long recovery time.

# Data

This project uses the "recovery.RData" file, which consists of 10000 participants. A random sample of 2000 participants is used for this analysis using a seed set to my UNI number (2183).

```{r}
set.seed(2183) # for reproducibility - my UNI

# read in dataset
load("data/recovery.Rdata")

# create a random sample of 2000 participants
dat <- dat[sample(1:10000, 2000),] 
```

Split the data into training (70%) and test (30%) sets

```{r}
set.seed(2183)

# specify rows of training data (70% of the dataset)
trRows <- createDataPartition(dat$recovery_time, p = 0.7, list = FALSE)


# training data
dat_train <- dat[trRows, ]
## matrix of predictors
x <- model.matrix(recovery_time~.,dat)[trRows,-1]
## vector of response
y <- dat$recovery_time[trRows]


# test data
dat_test <- dat[-trRows, ]
## matrix of predictors
x2 <- model.matrix(recovery_time~.,dat)[-trRows,-1]
## vector of response
y2 <- dat$recovery_time[-trRows]
```

# Exploratory analysis and data visualization:

In this section, use appropriate visualization techniques to explore the dataset and identify any patterns or relationships in the data.

```{r}
# create dataset for exploratory analysis and data visualization

dat_train_viz <- dat_train %>%
  mutate(study = case_when( # turn study (character variable) into a numeric variable
    study == "A" ~ 1,
    study == "B" ~ 2,
    study == "C" ~ 3))

# Find the remaining non-numeric columns
non_numeric_cols <- sapply(dat_train_viz, function(x) !is.numeric(x))

# Convert non-numeric columns to numeric
dat_train_viz[, non_numeric_cols] <- lapply(dat_train_viz[, non_numeric_cols], as.numeric) # turn factor variables into numeric variables
```

The following code creates lattice plots to visualize the the multivariate data. A plot is created for each of the 13 predictors in the dataset in order to visualize each predictor's association with the outcome, `recovery_time` (COVID-19 recovery time).

```{r}
# set various graphical parameters (color, line type, background, etc) to control the look of trellis displays
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x = dat_train_viz[ ,2:15],
            y = dat_train_viz[ ,16],
            plot = "scatter",
            span = .5,
            labels = c("Predictors (Xs)", "Recovery Time (Y)"),
            type = c("p", "smooth"))
```

[Based on the lattice plots above, the following patterns in the data can be observed: ]

# Model training:

In this section, describe the models you used for predicting time to recovery from COVID-19. State the assumptions made by using the models. Provide a detailed description of the model training procedure and how you obtained the final model.

## Less flexible models: 

Linear model: 

```{r}
set.seed(2183)

# 10-fold cross-validation repeated 5 times using the best rule
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

# Fit a linear regression model using cross-validation on the training dataset
linear_model <- train(recovery_time ~ age + gender + race + smoking + height + weight + 
                 bmi + hypertension + diabetes + SBP + LDL + vaccine + 
                 severity + study, 
               data = dat_train, 
               method = "lm", 
               trControl = ctrl)

# view the model summary and performance on the test set
summary(linear_model$finalModel)

# view performance on the test set (RMSE)
test_pred <- predict(linear_model, newdata = dat_test)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```

/*
We then use the train function from the caret package to fit a linear regression model to the training data using cross-validation with 10 folds. The trainControl function specifies the cross-validation method, and the method argument specifies the type of model to fit (in this case, linear regression). The resulting model object contains the final model and information about the cross-validation performance.

We can view the summary statistics for the final model using the summary function on the finalModel object within the model object. We can also use the predict function to generate predictions for the test set using the final model, and compute the root mean squared error (RMSE) between the predicted and actual recovery times on the test set.

This approach allows us to obtain a final model that has been trained using cross-validation, which can help to reduce overfitting and improve the generalization performance of the model on new, unseen data.
*/

Lasso model:

```{r}
set.seed(2183)

lasso_model <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-1, 5, length = 100))),
                   trControl = ctrl)

# view the model summary
summary(lasso_model$finalModel)

# view performance on the test set (RMSE)
test_pred <- predict(lasso_model, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```

Elastic net model:

```{r}
set.seed(2183)

enet_model <- train(x, y,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl)

# view the model summary
summary(enet_model$finalModel)

# view performance on the test set (RMSE)
test_pred <- predict(enet_model, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```

Partial least squares model:
```{r}
set.seed(2183)

pls_model <- train(x, y,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:15), # CHECK THIS
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

# view the model summary
summary(pls_model$finalModel)

# view performance on the test set (RMSE)
test_pred <- predict(pls_model, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```

## More flexible models: 

Generalized additive model (GAM):

```{r}
set.seed(2183)

# fit GAM using all predictors
gam_model_all <- train(x, y, # test dataset
                 method = "gam",
                 trControl = ctrl, # 10-fold CV
                 control = gam.control(maxit = 200)) # Adjusted due to failure to converge at default setting

# fit GAM using selection specification
gam_model_select <- train(x, y, # test dataset
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE)),
                 trControl = ctrl, # 10-fold CV
                 control = gam.control(maxit = 200))  # Adjusted due to failure to converge at default setting


# view performance on the test set (RMSE) for the model with all predictors
test_pred <- predict(gam_model_all, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 

# view performance on the test set (RMSE) for the model with select predictors
test_pred <- predict(gam_model_select, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```

Multivariate adaptive regression spline (MARS) model:

```{r}
set.seed(2183)

# create grid of all possible pairs that can take degree and nprune values
mars_grid <- expand.grid(degree = 1:3, # number of possible product hinge functions in 1 term
                         nprune = 2:15) # Upper bound of number of terms in model

mars_model <- train(x, y, # training dataset
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl)

# calculate rmse
# view performance on the test set (RMSE)
test_pred <- predict(mars_model, newdata = x2)
test_rmse <- sqrt(mean((test_pred - dat_test$recovery_time)^2))
test_rmse

# calculate RMSE
sqrt(mean((test_pred - y2)^2)) 
```


Model comparison:

```{r}
set.seed(2183)

resamp <- resamples(list(
  lm = linear_model,
  lasso = lasso_model,
  enet = enet_model,
  pls = pls_model,
  gam_all = gam_model_all,
  gam_select = gam_model_select,
  mars = mars_model
  ))

summary(resamp)

bwplot(resamp, metric = "RMSE")
```

# Results:

In this section, report the final model that you built for predicting time to recovery from COVID-19. Interpret the results. Assess the model's training/test performance.

```{r}
```

# Conclusions:

In this section, summarize your findings from the model analysis and discuss the insights gained into predicting time to recovery from COVID-19.

```{r}
```